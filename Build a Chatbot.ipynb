{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400c6c40-f9ee-42b0-b2af-8dcd1c640470",
   "metadata": {},
   "source": [
    "# Build a Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cc6b2f-2ae1-4df7-b263-17a7a6424af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-core langgraph>0.2.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d86ec0-3819-4bf2-924d-5b90ff7d7a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"langchain[groq]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f74937-1a36-4077-9ae9-568b0ec69868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8681841-1d11-4442-bfda-1b6259e223b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
    "os.environ['LANGSMITH_PROJECT'] = 'Build-a-Chatbot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7a2beff-d9f3-44b6-b58a-8de3c712fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGSMITH_TRACING='true'\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY=\"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\"\n",
    "LANGSMITH_PROJECT=\"Build-a-Chatbot\"\n",
    "\n",
    "GROQ_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70f21acf-e969-4a7a-b760-0669f346c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get('GROQ_API_KEY'):\n",
    "    os.environ['GROQ_API_KEY'] = getpass.getpass('Enter API key for Groq: ')\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model('llama3-8b-8192', model_provider = 'groq')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f739dc85-c34e-43ee-a348-a75fc463151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Ravi! How are you doing today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 16, 'total_tokens': 31, 'completion_time': 0.0125, 'prompt_time': 0.002405912, 'queue_time': 0.23695191999999998, 'total_time': 0.014905912}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_dadc9d6142', 'finish_reason': 'stop', 'logprobs': None}, id='run-4ddee4cc-90c6-4ff8-8d0e-46caaa49d8e4-0', usage_metadata={'input_tokens': 16, 'output_tokens': 15, 'total_tokens': 31})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content = 'Hi! I am Ravi')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7411292e-ea1a-4ae1-a60e-da6f82a364d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm happy to help! However, I'm a large language model, I don't have the ability to know your personal information, including your name. Each time you interact with me, it's a new conversation, and I don't retain any information from previous conversations. If you'd like to share your name with me, I'd be happy to learn it, but it's not necessary for our conversation.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 15, 'total_tokens': 99, 'completion_time': 0.07, 'prompt_time': 0.004425841, 'queue_time': 0.346869594, 'total_time': 0.074425841}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ab09b36-98aa-4f5e-869a-e1d60c5441ce-0', usage_metadata={'input_tokens': 15, 'output_tokens': 84, 'total_tokens': 99})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content = \"What's my name?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c49ffa-b633-42c1-870e-88dc45fef959",
   "metadata": {},
   "source": [
    "### Passing the entire conversation history into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed10b641-53ce-4ac7-b380-81adf453e74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Ravi!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 42, 'total_tokens': 49, 'completion_time': 0.005833333, 'prompt_time': 0.005585333, 'queue_time': 0.233984297, 'total_time': 0.011418666}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-fac5286a-cee9-483d-903a-6341f96a3455-0', usage_metadata={'input_tokens': 42, 'output_tokens': 7, 'total_tokens': 49})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "     HumanMessage(content = \"Hi! I'm Ravi\"),\n",
    "     AIMessage(content=\"Hello Ravi! How can I assist you today?\"),\n",
    "     HumanMessage(content = \"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f84c471-963f-4ada-b2e1-07daef5280cf",
   "metadata": {},
   "source": [
    "## Message Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30880e09-9588-4460-8689-8a77003a45c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema = MessagesState)\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer = memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3c4ad2-5d06-4f66-b67c-0c6a986ae0f1",
   "metadata": {},
   "source": [
    "### Creating a config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbcce8a4-04b2-451a-8fef-2ed73bb36d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "786d44f0-f50e-450e-9fad-ab387671a3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Ravi!\n"
     ]
    }
   ],
   "source": [
    "query = \"Haii, I'm Ravi.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ce8fa9e-9cde-4be8-82c3-694f57a81041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I remember! Your name is Ravi!\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4e87296-15ae-4f59-8fdf-aa91a6d0ee1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm happy to help! However, I'm a large language model, I don't have any information about your personal identity, including your name. Each time you interact with me, it's a new conversation and I don't retain any information about you. So, I don't actually know your name!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57bc5e-387f-4fb3-b31f-c2bd5a01844c",
   "metadata": {},
   "source": [
    "#### Going back to the Original Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bed02cc6-ed94-4f82-999a-ae9ce3a3308b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Ravi!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3650d2-596e-4f63-8a84-48706ce7a991",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c076b583-8d54-4b4a-ad84-530f8fe70116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef83efef-32c8-4676-88e5-2406025430ce",
   "metadata": {},
   "source": [
    "### Now we updating our application to incorporate this template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4dd205a-f71d-4d09-93f4-2b2065da0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema = MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3b5db05-992e-4d6d-8086-291c533691ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! I'm Jim.\n"
     ]
    }
   ],
   "source": [
    "# Invoking the application\n",
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hi! I'm Jim.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef4c54c2-502f-47bc-9ce3-6e8b1901fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is my name?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8365246-e0dc-423b-8f64-c7bf97890319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prompt complicated\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",        \n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name = \"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f487b09-189f-44da-a4c7-08781ed6d236",
   "metadata": {},
   "source": [
    "### Updating the State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d5d7c52-1657-4f97-8682-babf2d8725a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "workflow = StateGraph(state_schema = State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d9cd575-556d-4c2f-a53e-6ca5d9dae445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hola Bob! ¡Encantado de conocerte! (Hello Bob! Nice to meet you!) ¿En qué puedo ayudarte hoy? (What can I help you with today?)\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"Hi! I'm Bob.\"\n",
    "language = \"Spanish\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9acaf32c-9bc2-47c2-94c8-fdefb21e4169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Me llamo Asistente, soy un asistente virtual que está aquí para ayudarte con tus preguntas y necesidades. No tengo un nombre personal, pero puedo ayudarte con cualquier cosa que necesites. ¡Estoy aquí para ayudarte!\n"
     ]
    }
   ],
   "source": [
    "query = \"What is name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f48eae6-9f72-4c4b-bf2e-f01860c94e6e",
   "metadata": {},
   "source": [
    "## Managing Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ff0e0-5633-44f0-b379-4f86c6f6f8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aebe39-3238-42ac-8e2d-43dd5e5152e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db39c5-ca7d-4823-ad10-7535171b455f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
